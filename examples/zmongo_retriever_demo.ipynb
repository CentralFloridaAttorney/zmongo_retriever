{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from zmongo_retriever import ZMongoRetriever\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "from langchain.chains import load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = '/PycharmProjects/zcases/zassistant/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q4_0.gguf' # Your .gguf file path\n",
    "mongo_db_name = 'case_graph' # Your MongoDB database name\n",
    "mongo_uri = 'mongodb://localhost:49999' # Your mongo_uri\n",
    "this_collection_name = 'zcases'  # Your MongoDB collection\n",
    "this_page_content_field = 'opinion'  # Specify the field to use as page_content\n",
    "this_document_id = '65cf9acdb347eec24fd6b02a'  # Example ObjectId('_id') value\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed90eef6ccf7732c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# larger values for chunk_size may solve problems with exceeding your token limit\n",
    "retriever = ZMongoRetriever(mongo_uri=mongo_uri, chunk_size=1000, collection_name=this_collection_name, page_content_field=this_page_content_field)\n",
    "documents_by_id = retriever.invoke(this_document_id, query_by_id=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2ec06cdd1129dbd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "  \"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "llm = LlamaCpp(\n",
    "    model_path=os.getenv('MODEL_PATH'),\n",
    "    max_tokens=0,\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=4096,\n",
    "    n_batch=4096,\n",
    "    verbose=True,\n",
    "    f16_kv=True\n",
    ")\n",
    "stuff_chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3a44193a4d2cdd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summary_chain_result = stuff_chain.invoke({'input_documents': documents_by_id[0]})\n",
    "print(summary_chain_result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5dd6d716a1f8bdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
