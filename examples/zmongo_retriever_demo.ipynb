{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:09:56.507583409Z",
     "start_time": "2024-03-07T15:09:55.088744294Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from src.zmongo_retriever import ZMongoRetriever\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "from langchain.chains import load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set your variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b41e077475cc5f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = model_path_1 = '/mnt/storage/models/dolphin-2.1-mistral-7B-GGUF/dolphin-2.1-mistral-7b.Q4_0.gguf'\n",
    " # Your .gguf file path\n",
    "mongo_db_name = 'case_graph' # Your MongoDB database name\n",
    "mongo_uri = 'mongodb://localhost:49999' # Your mongo_uri\n",
    "this_collection_name = 'zcases'  # Your MongoDB collection\n",
    "this_page_content_field = 'opinion'  # Specify the field to use as page_content\n",
    "this_document_id = '65d9957e2051723e1bb6eec9'  # Example ObjectId('_id') value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:11:40.079478760Z",
     "start_time": "2024-03-07T15:11:40.025879543Z"
    }
   },
   "id": "ed90eef6ccf7732c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use ZMongoRetriever to split the text from the page_content_field into LangChain Documents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b32bf262a89edc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<zmongo_retriever.Document object at 0x7f0e2fbf6290>, <zmongo_retriever.Document object at 0x7f0e2fbf4550>, <zmongo_retriever.Document object at 0x7f0e2fbf4220>, <zmongo_retriever.Document object at 0x7f0e2fbf5c60>, <zmongo_retriever.Document object at 0x7f0e2fbf4790>, <zmongo_retriever.Document object at 0x7f0e2fbf4970>, <zmongo_retriever.Document object at 0x7f0e2fbf62f0>, <zmongo_retriever.Document object at 0x7f0e2fbf4c40>, <zmongo_retriever.Document object at 0x7f0e2fbf5750>, <zmongo_retriever.Document object at 0x7f0e2fbf5300>, <zmongo_retriever.Document object at 0x7f0e2fbf5720>, <zmongo_retriever.Document object at 0x7f0e2fbf4190>, <zmongo_retriever.Document object at 0x7f0e2fbf5060>]]\n"
     ]
    }
   ],
   "source": [
    "# larger values for chunk_size may solve problems with exceeding your token limit\n",
    "retriever = ZMongoRetriever(mongo_uri=mongo_uri, chunk_size=1000, collection_name=this_collection_name, page_content_field=this_page_content_field)\n",
    "documents_by_id = retriever.invoke(this_document_id, query_by_id=True)\n",
    "print(documents_by_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:11:46.022142439Z",
     "start_time": "2024-03-07T15:11:46.010323312Z"
    }
   },
   "id": "a2ec06cdd1129dbd",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use LlamaCPP to summarize the page_content_field"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2069a8a7a9b5a85"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /mnt/storage/models/dolphin-2.1-mistral-7B-GGUF/dolphin-2.1-mistral-7b.Q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = ehartford_dolphin-2.1-mistral-7b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 3.83 GiB (4.54 BPW) \n",
      "llm_load_print_meta: general.name     = ehartford_dolphin-2.1-mistral-7b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  3917.88 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =   192.08 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2304.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'ehartford_dolphin-2.1-mistral-7b', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n",
      "Using fallback chat format: None\n",
      "\n",
      "llama_print_timings:        load time =  380450.70 ms\n",
      "llama_print_timings:      sample time =      63.00 ms /   127 runs   (    0.50 ms per token,  2015.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  380448.55 ms /  2538 tokens (  149.90 ms per token,     6.67 tokens per second)\n",
      "llama_print_timings:        eval time =   26107.27 ms /   126 runs   (  207.20 ms per token,     4.83 tokens per second)\n",
      "llama_print_timings:       total time =  407020.92 ms /  2664 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_documents': [<zmongo_retriever.Document object at 0x7f0e2fbf6290>, <zmongo_retriever.Document object at 0x7f0e2fbf4550>, <zmongo_retriever.Document object at 0x7f0e2fbf4220>, <zmongo_retriever.Document object at 0x7f0e2fbf5c60>, <zmongo_retriever.Document object at 0x7f0e2fbf4790>, <zmongo_retriever.Document object at 0x7f0e2fbf4970>, <zmongo_retriever.Document object at 0x7f0e2fbf62f0>, <zmongo_retriever.Document object at 0x7f0e2fbf4c40>, <zmongo_retriever.Document object at 0x7f0e2fbf5750>, <zmongo_retriever.Document object at 0x7f0e2fbf5300>, <zmongo_retriever.Document object at 0x7f0e2fbf5720>, <zmongo_retriever.Document object at 0x7f0e2fbf4190>, <zmongo_retriever.Document object at 0x7f0e2fbf5060>], 'output_text': \"1. U.S. Bank failed to reestablish a lost note, so the final judgment of foreclosure is reversed.\\n  2. U.S. Bank's witness, Vonterro White, did not establish that the original lender was entitled to enforce the note when it was lost or whether the note was lost during a transfer or lawful seizure.\\n  3. The lost-note affidavit was not entered into evidence and did not specify that the prior servicer was entitled to enforce the note when it was lost or that the note was not lawfully seized or transferred.\"}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "  \"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "llm = LlamaCpp(\n",
    "    model_path=os.getenv('MODEL_PATH', '/mnt/storage/models/dolphin-2.1-mistral-7B-GGUF/dolphin-2.1-mistral-7b.Q4_0.gguf'),\n",
    "    max_tokens=0,\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=4096,\n",
    "    n_batch=4096,\n",
    "    verbose=True,\n",
    "    f16_kv=True\n",
    ")\n",
    "stuff_chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
    "summary_chain_result = stuff_chain.invoke({'input_documents': documents_by_id[0]})\n",
    "print(summary_chain_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:23:33.904453087Z",
     "start_time": "2024-03-07T15:16:38.423544664Z"
    }
   },
   "id": "f3a44193a4d2cdd5",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
