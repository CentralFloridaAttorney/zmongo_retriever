{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ecf31a37a9be31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This example requires you to get an OPENAI_API_KEY. \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d796788450209e60",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Jupyter-friendly version of ZRetriever usage\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from zmongo_toolbag.zmongo import ZMongo\n",
    "from zmongo_toolbag.zmongo_retriever import ZRetriever\n",
    "\n",
    "# Allow nested event loops for Jupyter compatibility\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the async logic directly\n",
    "async def run_zretriever_demo():\n",
    "    repo = ZMongo()\n",
    "    retriever = ZRetriever(repository=repo, max_tokens_per_set=4096, chunk_size=512)\n",
    "\n",
    "    # Replace with real collection name and document IDs\n",
    "    collection_name = 'documents'\n",
    "    document_ids = ['67e5ba645f74ae46ad39929d', '67ef0bd71a349c7c108331a6']\n",
    "\n",
    "    documents = await retriever.invoke(collection=collection_name, object_ids=document_ids, page_content_key='text')\n",
    "\n",
    "    for idx, doc_set in enumerate(documents):\n",
    "        print(f\"\\nDocument Set {idx + 1}:\")\n",
    "        for doc in doc_set:\n",
    "            print(f\"Metadata: {doc.metadata}\")\n",
    "            print(f\"Content: {doc.page_content[:200]}...\\n\")\n",
    "\n",
    "# Run the async function in Jupyter\n",
    "await run_zretriever_demo()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b41e077475cc5f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set your variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b32bf262a89edc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Use ZMongoRetriever to split the text from the page_content_field into LangChain Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2069a8a7a9b5a85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If the output from above == [] then you have a problem with your variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f17e023b1b92d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Use LlamaCPP to summarize the chunked output."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Jupyter cell: Combine ZRetriever with LlamaModel to query MongoDB and generate LLM completions\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from zmongo_toolbag.zmongo import ZMongo\n",
    "from zmongo_toolbag.zmongo_retriever import ZRetriever\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Load environment variables and allow nested asyncio\n",
    "load_dotenv('/home/overlordx/resources/.env')\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class LlamaModel:\n",
    "    def __init__(self):\n",
    "        self.model_path = os.getenv(\n",
    "            \"GGUF_MODEL_PATH\",\n",
    "\n",
    "        )\n",
    "        self.n_ctx = int(os.getenv(\"N_CTX\", 512))\n",
    "        self.n_batch = int(os.getenv(\"N_BATCH\", 126))\n",
    "        self.llm = None\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        print(\"Loading model...\")\n",
    "        self.llm = Llama(\n",
    "            model_path=self.model_path,\n",
    "            n_ctx=self.n_ctx,\n",
    "            n_batch=self.n_batch\n",
    "        )\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    def generate_prompt_from_template(self, user_input: str) -> str:\n",
    "        return (\n",
    "            \"<|im_start|>system\\n\"\n",
    "            \"You are a helpful chatbot.<|im_end|>\\n\"\n",
    "            \"<|im_start|>user\\n\"\n",
    "            f\"{user_input}<|im_end|>\"\n",
    "        )\n",
    "\n",
    "    def generate_text(self, prompt: str, max_tokens: int = 256, temperature: float = 0.1, top_p: float = 0.5, echo: bool = False, stop: list = None) -> str:\n",
    "        stop = stop or [\"#\"]\n",
    "        output = self.llm(\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            echo=echo,\n",
    "            stop=stop,\n",
    "        )\n",
    "        return output[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Main async function to retrieve and summarize using Llama\n",
    "async def run_llama_zretriever_pipeline():\n",
    "    repo = ZMongo()\n",
    "    retriever = ZRetriever(repository=repo, max_tokens_per_set=4096, chunk_size=512)\n",
    "    collection_name = 'documents'\n",
    "    document_ids = ['67e5ba645f74ae46ad39929d', '67ef0bd71a349c7c108331a6']\n",
    "\n",
    "    documents = await retriever.invoke(collection=collection_name, object_ids=document_ids, page_content_key='text')\n",
    "\n",
    "    llama_model = LlamaModel()\n",
    "\n",
    "    for idx, doc_set in enumerate(documents):\n",
    "        combined_text = \"\\n\\n\".join(doc.page_content for doc in doc_set)\n",
    "        print(f\"\\nDocument Set {idx + 1} (retrieved {len(doc_set)} chunks):\")\n",
    "        prompt = llama_model.generate_prompt_from_template(\n",
    "            f\"Summarize the following legal content for a law student:\\n{combined_text[:1000]}\"\n",
    "        )\n",
    "        summary = llama_model.generate_text(prompt, max_tokens=512)\n",
    "        print(\"\\nSummary:\")\n",
    "        print(summary)\n",
    "\n",
    "# Run in notebook\n",
    "await run_llama_zretriever_pipeline()\n"
   ],
   "id": "3c70e0bbe299743d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Jupyter cell: Combine ZRetriever with OpenAIModel to query MongoDB and generate completions\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from bson import ObjectId\n",
    "from dotenv import load_dotenv\n",
    "from zmongo_toolbag.zmongo import ZMongo\n",
    "from zmongo_toolbag.zmongo_retriever import ZRetriever\n",
    "import openai\n",
    "\n",
    "# Load environment variables and allow nested asyncio\n",
    "load_dotenv('/home/overlordx/resources/.env')\n",
    "nest_asyncio.apply()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY_APP\")\n",
    "\n",
    "class OpenAIModel:\n",
    "    def __init__(self):\n",
    "        self.model = os.getenv(\"OPENAI_TEXT_MODEL\", \"gpt-3.5-turbo-instruct\")\n",
    "        self.max_tokens = int(os.getenv(\"DEFAULT_MAX_TOKENS\", 256))\n",
    "        self.temperature = float(os.getenv(\"DEFAULT_TEMPERATURE\", 0.7))\n",
    "        self.top_p = float(os.getenv(\"DEFAULT_TOP_P\", 0.95))\n",
    "\n",
    "    async def _call_openai(self, prompt: str, max_tokens=None, temperature=None, top_p=None, stop=None, echo=False) -> str:\n",
    "        try:\n",
    "            response = await asyncio.to_thread(openai.completions.create,\n",
    "                model=self.model,\n",
    "                prompt=prompt,\n",
    "                max_tokens=max_tokens or self.max_tokens,\n",
    "                temperature=temperature or self.temperature,\n",
    "                top_p=top_p or self.top_p,\n",
    "                stop=stop,\n",
    "                echo=echo,\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            return f\"[OpenAI Error] {e}\"\n",
    "\n",
    "    async def summarize_text(self, text: str) -> str:\n",
    "        prompt = f\"Summarize the following for a legal researcher:\\n\\n{text}\\n\\nSummary:\"\n",
    "        return await self._call_openai(prompt, max_tokens=200)\n",
    "\n",
    "# Main async function to retrieve and summarize using OpenAI\n",
    "async def run_openai_zretriever_pipeline():\n",
    "    repo = ZMongo()\n",
    "    retriever = ZRetriever(repository=repo, max_tokens_per_set=4096, chunk_size=512)\n",
    "    collection_name = 'documents'\n",
    "    document_ids = ['67e5ba645f74ae46ad39929d', '67ef0bd71a349c7c108331a6']\n",
    "\n",
    "    documents = await retriever.invoke(collection=collection_name, object_ids=document_ids, page_content_key='text')\n",
    "    openai_model = OpenAIModel()\n",
    "\n",
    "    for idx, doc_set in enumerate(documents):\n",
    "        combined_text = \"\\n\\n\".join(doc.page_content for doc in doc_set)\n",
    "        print(f\"\\nDocument Set {idx + 1} (retrieved {len(doc_set)} chunks):\")\n",
    "        summary = await openai_model.summarize_text(combined_text[:1000])\n",
    "        print(\"\\nSummary:\")\n",
    "        print(summary)\n",
    "\n",
    "# Run in notebook\n",
    "await run_openai_zretriever_pipeline()\n"
   ],
   "id": "c133de937b43e97e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
